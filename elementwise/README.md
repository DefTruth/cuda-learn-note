# Elementwise

## 0x00 说明

包含以下内容：

- [X] elementwise_add_f32_kernel
- [X] elementwise_add_f32x4_kernel(float4向量化版本)
- [X] elementwise_add_f16_kernel(fp16版本)
- [X] elementwise_add_f16x2_kernel(fp16向量化版本)
- [X] PyTorch bindings


## 测试

```bash
# 只测试Ada架构 不指定默认编译所有架构 耗时较长
export TORCH_CUDA_ARCH_LIST=Ada 
python3 elementwise.py
```

输出:

```bash
--------------------------------------------------------------------------------
       out_f32: [-1.551710605621338, 0.636202335357666], time:0.01121569ms
     out_f32x4: [-1.551710605621338, 0.636202335357666], time:0.01115274ms
    out_f32_th: [-1.551710605621338, 0.636202335357666], time:0.00764298ms
--------------------------------------------------------------------------------
       out_f16: [-1.5517578125, 0.6357421875], time:0.01118946ms
     out_f16x2: [-1.5517578125, 0.6357421875], time:0.01107597ms
    out_f16_th: [-1.5517578125, 0.6357421875], time:0.00757146ms
--------------------------------------------------------------------------------
   out_f32(v2): [-1.551710605621338, 0.636202335357666], time:0.00353050ms
 out_f32x4(v2): [-1.551710605621338, 0.636202335357666], time:0.00479841ms
    out_f32_th: [-1.551710605621338, 0.636202335357666], time:0.00594687ms
--------------------------------------------------------------------------------
   out_f16(v2): [-1.5517578125, 0.6357421875], time:0.00358319ms
 out_f16x2(v2): [-1.5517578125, 0.6357421875], time:0.00352454ms
    out_f16_th: [-1.5517578125, 0.6357421875], time:0.00592446ms
--------------------------------------------------------------------------------
```
