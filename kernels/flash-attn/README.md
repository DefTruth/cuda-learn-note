## ⚡️⚡️FlashAttention-2 MMA: Write FlashAttention using Tensor Cores with pure MMA PTX 

|CUDA Cores|Sliced K (Loop over N/D)|Tile Block (Br, Bc, Bd)|MMA (m16n8k16)|
|:---:|:---:|:---:|:---:|
|✔️|✔️|✔️|✔️|
|Pack LDST (pack 128 bits)|SMEM Padding|Copy Async (cp.async.cg/ca)|Tile MMA (More Threads)
|✔️|✔️|✔️|✔️|
|Tile Warp (More Values)|Multi Stages (1/2)|Collective Store (Warp Shuffle & Reg Reuse)|Row Major (NN)|
|✔️|✔️|✔️|✔️|

## 📖 说明

包含以下内容：(性能持续优化中，敬请期待...)

- [X] flash_attn_cuda_kernel (F32)
- [x] flash_attn_mma_naive_kernel (ldmatrix + MMA)
- [X] flash_attn_mma_stage_kernel (ldmatrix + MMA, Stages, Tile MMA/Warp, Copy Async, Collective Store, SMEM Padding)

本仓库FlashAttention仅用于学习CUDA编程，考虑性能最优请使用FlashAttention官方版本：[flash-attention](https://github.com/Dao-AILab/flash-attention)

## 📖 Kernel 调用
- flash_attn_mma_stage_kernel:
```C++
template<
         const int kHeadDim,          // Headdim, 32,64,128     
         const int kMmaAtomM,         // MMA Atom M, 16
         const int kMmaAtomN,         // MMA Atom N, 8
         const int kMmaAtomK,         // MMA Atom K, 16
         const int kMmaTileSeqLenQ,   // 2, more MMA(warp), M=16*2=32, Q@K^T=[Br(M), d(K)]@[d(K),  Bc(N)]  
         const int kMmaTileSeqLenK,   // 4, more MMA(warp), N=8*4= 32, Q@K^T=[Br(M), d(K)]@[d(K),  Bc(N)]    
         const int kMmaTileSeqLenP,   // 2, more MMA(warp), M=16*2=32, P@V  =[Br(M),Bc(K)]@[Bc(K), d(N) ]
         const int kMmaTileHeadDimV,  // 4, more MMA(warp), N=8*4= 32, P@V  =[Br(M),Bc(K)]@[Bc(K), d(N) ]       
         const int kWarpTileSeqLenQ,  // 2, more values, M, Br=32*2=64, matmul M 
         const int kWarpTileSeqLenK,  // 2, more values, N, Bc=32*2=64, matmul N
         const int kWarpTileSeqLenP,  // 2, more values, M, Br=32*2=64, matmul M
         const int kWarpTileHeadDimV, // 2, more values, N, d=32*(1|2|3|4|...)=32|64|96|128|...
         const int kStage,            // Multi-Stages, only support 1/2.
         const int kPad               // 0,8
         >
__global__ void __launch_bounds__(
  WARP_SIZE * kMmaTileSeqLenQ * kMmaTileSeqLenK) 
flash_attn_mma_stages_kernel(half* Q, 
                             half* K, 
                             half* V, 
                             half* O, 
                             int QKV_seqlen) {
}
```

## 📖 目前性能

目前，在小规模Attention(SeqLen<=4096)的情形，本仓库实现的flash-atttenion-mma基本持平或略优于FA官方的性能，在大规模Attention计算，仍然有较大的性能差距。性能持续优化中，敬请期待~ 性能测试示例如下：（NVIDIA L20）

- B=2, H=2, N=4096, D=64
  
```bash
python3 flash_attn_mma.py --naive --B 2 --H 2 --D 64 --N 4096
----------------------------------------------------------------------------------------------------
          B: batch_size, H: n_head, N: seq_len, D: head_dim, seed: 8942, Warmup: 2, Iters: 10
----------------------------------------------------------------------------------------------------
                         B=2, H=2, N=4096, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.03945923 ', '0.01776123  ', '0.02627563  '], time:1.318264ms
          mma(naive): ['-0.03945923 ', '0.01774597  ', '0.02626038  '], time:9.853077ms
         mma(stage1): ['-0.03945923 ', '0.01776123  ', '0.02624512  '], time:0.336719ms
         mma(stage2): ['-0.03945923 ', '0.01776123  ', '0.02624512  '], time:0.304818ms
             (flash): ['-0.03945923 ', '0.01776123  ', '0.02626038  '], time:0.328016ms
----------------------------------------------------------------------------------------------------
```

- B=2, H=2, N=4096, D=128
  
```bash
python3 flash_attn_mma.py --naive --B 2 --H 2 --D 128 --N 4096
----------------------------------------------------------------------------------------------------
          B: batch_size, H: n_head, N: seq_len, D: head_dim, seed: 2806, Warmup: 2, Iters: 10
----------------------------------------------------------------------------------------------------
                         B=2, H=2, N=4096, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.00286484  ', '-0.00598907 ', '-0.02156067 '], time:1.377940ms
          mma(naive): ['0.00284004  ', '-0.00598526 ', '-0.02157593 '], time:19.166064ms
         mma(stage1): ['0.00284004  ', '-0.00598526 ', '-0.02156067 '], time:0.678110ms
         mma(stage2): ['0.00284004  ', '-0.00598526 ', '-0.02156067 '], time:0.659609ms
             (flash): ['0.0028553   ', '-0.00598145 ', '-0.02156067 '], time:0.548506ms
----------------------------------------------------------------------------------------------------
```

- B=2, H=2, N=1024, D=128
  
```bash
python3 flash_attn_mma.py --naive --B 2 --H 2 --D 128 --N 1024
----------------------------------------------------------------------------------------------------
          B: batch_size, H: n_head, N: seq_len, D: head_dim, seed: 4166, Warmup: 2, Iters: 10
----------------------------------------------------------------------------------------------------
                         B=2, H=2, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.02110291 ', '0.04946899  ', '-0.04928589 '], time:0.145769ms
          mma(naive): ['-0.02116394 ', '0.04946899  ', '-0.04946899 '], time:1.236653ms
         mma(stage1): ['-0.02114868 ', '0.04943848  ', '-0.04943848 '], time:0.070930ms
         mma(stage2): ['-0.02114868 ', '0.04943848  ', '-0.04943848 '], time:0.069165ms
             (flash): ['-0.02113342 ', '0.04949951  ', '-0.04931641 '], time:0.151205ms
----------------------------------------------------------------------------------------------------
```

- B=2, H=2, N=8192, D=64
```bash
python3 flash_attn_mma.py --naive --B 2 --H 2 --D 64 --N 8192
----------------------------------------------------------------------------------------------------
          B: batch_size, H: n_head, N: seq_len, D: head_dim, seed: 434, Warmup: 2, Iters: 10
----------------------------------------------------------------------------------------------------
                         B=2, H=2, N=8192, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.00259781 ', '-0.00584412 ', '-0.00161552 '], time:5.139947ms
          mma(naive): ['-0.00258827 ', '-0.00583267 ', '-0.00162792 '], time:39.265347ms
         mma(stage1): ['-0.00261307 ', '-0.00583267 ', '-0.00162888 '], time:1.131415ms
         mma(stage2): ['-0.00261307 ', '-0.00583267 ', '-0.00162888 '], time:1.082253ms
             (flash): ['-0.00259209 ', '-0.00584793 ', '-0.00160122 '], time:0.786042ms
----------------------------------------------------------------------------------------------------
```

## 📖 运行测试   
```bash
# 只测试Ada架构 不指定默认编译所有架构 耗时较长: Volta, Ampere, Ada, Hopper, ...
pip install flash-attn
export TORCH_CUDA_ARCH_LIST=Ada 
python3 flash_attn_mma.py
```

- NVIDIA L20
```bash
python3 flash_attn_mma.py --naive --N 4096 --B 2 --H 2 --D 128
----------------------------------------------------------------------------------------------------
          B: batch_size, H: n_head, N: seq_len, D: head_dim, seed: 762, Warmup: 2, Iters: 10
----------------------------------------------------------------------------------------------------
                         B=2, H=2, N=4096, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.06402588  ', '0.01030731  ', '0.02693176  '], time:1.380467ms
          mma(naive): ['0.06408691  ', '0.01036835  ', '0.0269165   '], time:19.160128ms
         mma(stage1): ['0.06390381  ', '0.01038361  ', '0.02685547  '], time:0.681663ms
         mma(stage2): ['0.06390381  ', '0.01038361  ', '0.02685547  '], time:0.661945ms
             (flash): ['0.06402588  ', '0.01029968  ', '0.02694702  '], time:0.550222ms
----------------------------------------------------------------------------------------------------
```

- 更多日志如下：
```bash
----------------------------------------------------------------------------------------------------
          B: batch_size, H: n_head, N: seq_len, D: head_dim, seed: 4791, Warmup: 2, Iters: 10
----------------------------------------------------------------------------------------------------
                         B=1, H=1, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.02313232 ', '-0.0690918  ', '0.01024628  '], time:0.096679ms
          mma(naive): ['-0.02304077 ', '-0.0690918  ', '0.01034546  '], time:0.627875ms
         mma(stage1): ['-0.02307129 ', '-0.06915283 ', '0.01036835  '], time:0.049162ms
         mma(stage2): ['-0.02307129 ', '-0.06915283 ', '0.01036835  '], time:0.044727ms
             (flash): ['-0.02305603 ', '-0.06915283 ', '0.01024628  '], time:0.114155ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=1, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.02102661  ', '-0.05181885 ', '-0.05075073 '], time:0.098372ms
          mma(naive): ['0.02102661  ', '-0.05178833 ', '-0.05081177 '], time:1.219583ms
         mma(stage1): ['0.02101135  ', '-0.05175781 ', '-0.0508728  '], time:0.069022ms
         mma(stage2): ['0.02101135  ', '-0.05175781 ', '-0.0508728  '], time:0.065708ms
             (flash): ['0.02110291  ', '-0.05181885 ', '-0.05075073 '], time:0.122333ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=1, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.04943848 ', '0.03289795  ', '0.03292847  '], time:0.145054ms
          mma(naive): ['-0.04937744 ', '0.03283691  ', '0.03292847  '], time:2.422976ms
         mma(stage1): ['-0.04946899 ', '0.03283691  ', '0.03292847  '], time:0.084805ms
         mma(stage2): ['-0.04946899 ', '0.03283691  ', '0.03292847  '], time:0.075865ms
             (flash): ['-0.04940796 ', '0.03283691  ', '0.03295898  '], time:0.123882ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=1, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.04684448  ', '0.04428101  ', '-0.0496521  '], time:0.155616ms
          mma(naive): ['0.04684448  ', '0.04425049  ', '-0.04962158 '], time:4.777288ms
         mma(stage1): ['0.046875    ', '0.04421997  ', '-0.0496521  '], time:0.124383ms
         mma(stage2): ['0.046875    ', '0.04421997  ', '-0.0496521  '], time:0.116611ms
             (flash): ['0.04684448  ', '0.04428101  ', '-0.0496521  '], time:0.151396ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=4, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['0.02505493  ', '-0.03884888 ', '0.03839111  '], time:0.114441ms
          mma(naive): ['0.02503967  ', '-0.03878784 ', '0.03833008  '], time:0.641346ms
         mma(stage1): ['0.02502441  ', '-0.03881836 ', '0.03833008  '], time:0.051594ms
         mma(stage2): ['0.02502441  ', '-0.03881836 ', '0.03833008  '], time:0.046849ms
             (flash): ['0.02508545  ', '-0.03890991 ', '0.03842163  '], time:0.159287ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=4, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.05755615  ', '-0.0489502  ', '-0.065979   '], time:0.128007ms
          mma(naive): ['0.05743408  ', '-0.04898071 ', '-0.065979   '], time:1.237154ms
         mma(stage1): ['0.05749512  ', '-0.0489502  ', '-0.065979   '], time:0.071168ms
         mma(stage2): ['0.05749512  ', '-0.0489502  ', '-0.065979   '], time:0.068855ms
             (flash): ['0.05752563  ', '-0.04898071 ', '-0.065979   '], time:0.171375ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=4, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.02835083 ', '0.00565338  ', '0.05978394  '], time:0.321698ms
          mma(naive): ['-0.02848816 ', '0.00557709  ', '0.05969238  '], time:2.502728ms
         mma(stage1): ['-0.02851868 ', '0.00556564  ', '0.0597229   '], time:0.111842ms
         mma(stage2): ['-0.02851868 ', '0.00556564  ', '0.0597229   '], time:0.107741ms
             (flash): ['-0.02844238 ', '0.00562286  ', '0.0597229   '], time:0.164914ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=4, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.0413208   ', '-0.01803589 ', '0.00205803  '], time:0.341320ms
          mma(naive): ['0.04135132  ', '-0.01794434 ', '0.00203705  '], time:4.843640ms
         mma(stage1): ['0.04138184  ', '-0.01802063 ', '0.00209618  '], time:0.237679ms
         mma(stage2): ['0.04138184  ', '-0.01802063 ', '0.00209618  '], time:0.232315ms
             (flash): ['0.04135132  ', '-0.01802063 ', '0.00205231  '], time:0.219083ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=8, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['0.06848145  ', '-0.03616333 ', '-0.02568054 '], time:0.139976ms
          mma(naive): ['0.06842041  ', '-0.03619385 ', '-0.02557373 '], time:0.642300ms
         mma(stage1): ['0.06848145  ', '-0.03619385 ', '-0.02557373 '], time:0.064182ms
         mma(stage2): ['0.06848145  ', '-0.03619385 ', '-0.02557373 '], time:0.062895ms
             (flash): ['0.06848145  ', '-0.03613281 ', '-0.02572632 '], time:0.141335ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=8, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.02468872 ', '0.01733398  ', '-0.06427002 '], time:0.161743ms
          mma(naive): ['-0.02461243 ', '0.0173645   ', '-0.06433105 '], time:1.234579ms
         mma(stage1): ['-0.02459717 ', '0.01733398  ', '-0.06439209 '], time:0.131607ms
         mma(stage2): ['-0.02459717 ', '0.01733398  ', '-0.06439209 '], time:0.125146ms
             (flash): ['-0.02471924 ', '0.01733398  ', '-0.06420898 '], time:0.172949ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=8, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.05279541 ', '0.0152359   ', '0.01768494  '], time:0.682831ms
          mma(naive): ['-0.05279541 ', '0.01522827  ', '0.01771545  '], time:2.491093ms
         mma(stage1): ['-0.05282593 ', '0.01521301  ', '0.01768494  '], time:0.177312ms
         mma(stage2): ['-0.05282593 ', '0.01521301  ', '0.01768494  '], time:0.162506ms
             (flash): ['-0.05279541 ', '0.0152359   ', '0.01768494  '], time:0.208259ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=1, H=8, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.00988007 ', '-0.07843018 ', '-0.04537964 '], time:0.758100ms
          mma(naive): ['-0.00988007 ', '-0.07836914 ', '-0.04541016 '], time:4.834414ms
         mma(stage1): ['-0.00990295 ', '-0.07830811 ', '-0.04544067 '], time:0.354052ms
         mma(stage2): ['-0.00990295 ', '-0.07830811 ', '-0.04544067 '], time:0.341821ms
             (flash): ['-0.00987244 ', '-0.07843018 ', '-0.04541016 '], time:0.322461ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=1, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['0.0115509   ', '-0.06903076 ', '-0.07427979 '], time:0.104880ms
          mma(naive): ['0.01156616  ', '-0.06903076 ', '-0.07427979 '], time:0.631714ms
         mma(stage1): ['0.01158142  ', '-0.06896973 ', '-0.07427979 '], time:0.050020ms
         mma(stage2): ['0.01158142  ', '-0.06896973 ', '-0.07427979 '], time:0.045276ms
             (flash): ['0.01151276  ', '-0.06903076 ', '-0.07427979 '], time:0.116420ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=1, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.01117706  ', '0.01002502  ', '-0.05667114 '], time:0.106740ms
          mma(naive): ['0.01112366  ', '0.01013184  ', '-0.05661011 '], time:1.222134ms
         mma(stage1): ['0.01113892  ', '0.01016998  ', '-0.05661011 '], time:0.069237ms
         mma(stage2): ['0.01113892  ', '0.01016998  ', '-0.05661011 '], time:0.065756ms
             (flash): ['0.01117706  ', '0.01009369  ', '-0.05667114 '], time:0.127745ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=1, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.01078033 ', '0.0486145   ', '-0.02133179 '], time:0.206518ms
          mma(naive): ['-0.01079559 ', '0.0486145   ', '-0.02133179 '], time:2.455759ms
         mma(stage1): ['-0.01078033 ', '0.04867554  ', '-0.02133179 '], time:0.086260ms
         mma(stage2): ['-0.01078033 ', '0.04867554  ', '-0.02133179 '], time:0.076795ms
             (flash): ['-0.01076508 ', '0.0486145   ', '-0.02130127 '], time:0.140572ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=1, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.02957153 ', '-0.05664062 ', '0.00559998  '], time:0.215340ms
          mma(naive): ['-0.02957153 ', '-0.05667114 ', '0.00561523  '], time:4.799604ms
         mma(stage1): ['-0.02952576 ', '-0.05661011 ', '0.00555038  '], time:0.126314ms
         mma(stage2): ['-0.02952576 ', '-0.05661011 ', '0.00555038  '], time:0.123835ms
             (flash): ['-0.02960205 ', '-0.05667114 ', '0.0055809   '], time:0.169039ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=4, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.05426025 ', '-0.04974365 ', '0.03216553  '], time:0.140238ms
          mma(naive): ['-0.05422974 ', '-0.04974365 ', '0.03216553  '], time:0.640368ms
         mma(stage1): ['-0.05422974 ', '-0.04971313 ', '0.03225708  '], time:0.063801ms
         mma(stage2): ['-0.05422974 ', '-0.04971313 ', '0.03225708  '], time:0.062037ms
             (flash): ['-0.05426025 ', '-0.04980469 ', '0.03216553  '], time:0.138855ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=4, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.01756287  ', '0.04769897  ', '0.03887939  '], time:0.163817ms
          mma(naive): ['0.0176239   ', '0.04779053  ', '0.03903198  '], time:1.236463ms
         mma(stage1): ['0.01760864  ', '0.04772949  ', '0.0390625   '], time:0.131607ms
         mma(stage2): ['0.01760864  ', '0.04772949  ', '0.0390625   '], time:0.124693ms
             (flash): ['0.01759338  ', '0.04776001  ', '0.03890991  '], time:0.167727ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=4, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['0.02493286  ', '-0.01035309 ', '-0.01535797 '], time:0.681067ms
          mma(naive): ['0.02497864  ', '-0.01041412 ', '-0.01535797 '], time:2.491713ms
         mma(stage1): ['0.02500916  ', '-0.01036072 ', '-0.01535797 '], time:0.177479ms
         mma(stage2): ['0.02500916  ', '-0.01036072 ', '-0.01535797 '], time:0.161791ms
             (flash): ['0.02494812  ', '-0.01035309 ', '-0.0153656  '], time:0.207233ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=4, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.05224609 ', '0.05612183  ', '-0.00789642 '], time:0.755811ms
          mma(naive): ['-0.05227661 ', '0.05609131  ', '-0.00796509 '], time:4.834819ms
         mma(stage1): ['-0.05230713 ', '0.05609131  ', '-0.00799561 '], time:0.354147ms
         mma(stage2): ['-0.05230713 ', '0.05609131  ', '-0.00799561 '], time:0.342011ms
             (flash): ['-0.05227661 ', '0.05612183  ', '-0.00790405 '], time:0.317454ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=8, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.10241699 ', '0.0279541   ', '0.0413208   '], time:0.255227ms
          mma(naive): ['-0.10229492 ', '0.02796936  ', '0.0413208   '], time:0.641489ms
         mma(stage1): ['-0.10235596 ', '0.02799988  ', '0.04135132  '], time:0.097919ms
         mma(stage2): ['-0.10235596 ', '0.02799988  ', '0.04135132  '], time:0.090098ms
             (flash): ['-0.10235596 ', '0.02792358  ', '0.04129028  '], time:0.148273ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=8, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.00484085  ', '-0.09161377 ', '-0.05404663 '], time:0.302172ms
          mma(naive): ['0.00475311  ', '-0.0914917  ', '-0.0539856  '], time:1.234841ms
         mma(stage1): ['0.004776    ', '-0.0914917  ', '-0.05404663 '], time:0.194931ms
         mma(stage2): ['0.004776    ', '-0.0914917  ', '-0.05404663 '], time:0.180697ms
             (flash): ['0.00481796  ', '-0.09161377 ', '-0.05404663 '], time:0.204754ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=8, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.01339722 ', '-0.00278282 ', '0.05957031  '], time:1.561284ms
          mma(naive): ['-0.01334381 ', '-0.0027523  ', '0.05957031  '], time:2.487493ms
         mma(stage1): ['-0.01335907 ', '-0.00276947 ', '0.05953979  '], time:0.299239ms
         mma(stage2): ['-0.01335907 ', '-0.00276947 ', '0.05953979  '], time:0.286341ms
             (flash): ['-0.01339722 ', '-0.00278664 ', '0.05960083  '], time:0.265479ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=2, H=8, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.01472473 ', '0.01069641  ', '0.00494003  '], time:1.626682ms
          mma(naive): ['-0.01460266 ', '0.01072693  ', '0.00496674  '], time:4.847050ms
         mma(stage1): ['-0.01470184 ', '0.0107193   ', '0.00500488  '], time:0.680041ms
         mma(stage2): ['-0.01470184 ', '0.0107193   ', '0.00500488  '], time:0.667119ms
             (flash): ['-0.01469421 ', '0.01070404  ', '0.00495911  '], time:0.430512ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=1, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.01221466 ', '-0.0252533  ', '0.02658081  '], time:0.113845ms
          mma(naive): ['-0.01217651 ', '-0.02531433 ', '0.02661133  '], time:0.644326ms
         mma(stage1): ['-0.01215363 ', '-0.02522278 ', '0.02659607  '], time:0.050974ms
         mma(stage2): ['-0.01215363 ', '-0.02522278 ', '0.02659607  '], time:0.046182ms
             (flash): ['-0.0121994  ', '-0.0252533  ', '0.02659607  '], time:0.124216ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=1, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.15124512 ', '-0.00973511 ', '-0.04898071 '], time:0.126386ms
          mma(naive): ['-0.15124512 ', '-0.00974274 ', '-0.0489502  '], time:1.234722ms
         mma(stage1): ['-0.15112305 ', '-0.00977325 ', '-0.0489502  '], time:0.070763ms
         mma(stage2): ['-0.15112305 ', '-0.00977325 ', '-0.0489502  '], time:0.068855ms
             (flash): ['-0.15136719 ', '-0.009758   ', '-0.04898071 '], time:0.144768ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=1, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['0.00852203  ', '0.03509521  ', '-0.01040649 '], time:0.322938ms
          mma(naive): ['0.00856018  ', '0.0350647   ', '-0.01039124 '], time:2.482176ms
         mma(stage1): ['0.00857544  ', '0.03512573  ', '-0.01041412 '], time:0.111032ms
         mma(stage2): ['0.00857544  ', '0.03512573  ', '-0.01041412 '], time:0.107479ms
             (flash): ['0.00852966  ', '0.03509521  ', '-0.01039124 '], time:0.162792ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=1, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.02624512  ', '-0.0218811  ', '0.00286674  '], time:0.342917ms
          mma(naive): ['0.02622986  ', '-0.02198792 ', '0.00295258  '], time:4.843545ms
         mma(stage1): ['0.02619934  ', '-0.02203369 ', '0.00297737  '], time:0.238228ms
         mma(stage2): ['0.02619934  ', '-0.02203369 ', '0.00297737  '], time:0.232315ms
             (flash): ['0.02624512  ', '-0.02191162 ', '0.00291061  '], time:0.219464ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=4, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.02259827 ', '-0.04086304 ', '-0.01893616 '], time:0.237060ms
          mma(naive): ['-0.02270508 ', '-0.04071045 ', '-0.01905823 '], time:0.642824ms
         mma(stage1): ['-0.02276611 ', '-0.04071045 ', '-0.01899719 '], time:0.098085ms
         mma(stage2): ['-0.02276611 ', '-0.04071045 ', '-0.01899719 '], time:0.090194ms
             (flash): ['-0.0226593  ', '-0.040802   ', '-0.01896667 '], time:0.148749ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=4, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.03939819 ', '-0.020401   ', '0.06835938  '], time:0.305700ms
          mma(naive): ['-0.03936768 ', '-0.02033997 ', '0.06835938  '], time:1.237082ms
         mma(stage1): ['-0.03936768 ', '-0.02037048 ', '0.0682373   '], time:0.191927ms
         mma(stage2): ['-0.03936768 ', '-0.02037048 ', '0.0682373   '], time:0.181007ms
             (flash): ['-0.03942871 ', '-0.02038574 ', '0.06835938  '], time:0.202513ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=4, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.00169182 ', '-0.03265381 ', '-0.01131439 '], time:1.560163ms
          mma(naive): ['-0.00167274 ', '-0.03265381 ', '-0.01129913 '], time:2.554107ms
         mma(stage1): ['-0.00167847 ', '-0.03265381 ', '-0.01128387 '], time:0.299549ms
         mma(stage2): ['-0.00167847 ', '-0.03265381 ', '-0.01128387 '], time:0.286245ms
             (flash): ['-0.00166225 ', '-0.03265381 ', '-0.0112915  '], time:0.265408ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=4, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['0.00659943  ', '0.01834106  ', '-0.01256561 '], time:1.623297ms
          mma(naive): ['0.00662994  ', '0.01834106  ', '-0.01259613 '], time:4.849243ms
         mma(stage1): ['0.00666428  ', '0.01835632  ', '-0.0125885  '], time:0.682616ms
         mma(stage2): ['0.00666428  ', '0.01835632  ', '-0.0125885  '], time:0.666404ms
             (flash): ['0.0066185   ', '0.01834106  ', '-0.0125885  '], time:0.430489ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=8, N=1024, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['0.1619873   ', '-0.02633667 ', '-0.07122803 '], time:0.614214ms
          mma(naive): ['0.16186523  ', '-0.02633667 ', '-0.07128906 '], time:0.641060ms
         mma(stage1): ['0.16186523  ', '-0.02638245 ', '-0.07122803 '], time:0.160074ms
         mma(stage2): ['0.16186523  ', '-0.02638245 ', '-0.07122803 '], time:0.153947ms
             (flash): ['0.1619873   ', '-0.02633667 ', '-0.07128906 '], time:0.179791ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=8, N=1024, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.01779175 ', '0.00307846  ', '0.03710938  '], time:0.656843ms
          mma(naive): ['-0.01780701 ', '0.00312424  ', '0.0369873   '], time:1.240921ms
         mma(stage1): ['-0.01782227 ', '0.00312233  ', '0.0369873   '], time:0.357890ms
         mma(stage2): ['-0.01782227 ', '0.00312233  ', '0.0369873   '], time:0.345254ms
             (flash): ['-0.01786804 ', '0.00312233  ', '0.03707886  '], time:0.260258ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=8, N=2048, D=64, Warmup: 2, Iters: 10
      naive(unfused): ['-0.01933289 ', '0.00508499  ', '0.00285912  '], time:3.031611ms
          mma(naive): ['-0.01930237 ', '0.00502014  ', '0.0028553   '], time:2.496433ms
         mma(stage1): ['-0.01933289 ', '0.00498962  ', '0.00286484  '], time:0.574112ms
         mma(stage2): ['-0.01933289 ', '0.00498962  ', '0.00286484  '], time:0.547338ms
             (flash): ['-0.0193634  ', '0.00505829  ', '0.00289345  '], time:0.430322ms
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
                         B=4, H=8, N=2048, D=128, Warmup: 2, Iters: 10
      naive(unfused): ['-0.05450439 ', '-0.03857422 ', '0.00600052  '], time:3.121519ms
          mma(naive): ['-0.05447388 ', '-0.03863525 ', '0.00599289  '], time:4.852891ms
         mma(stage1): ['-0.05450439 ', '-0.03857422 ', '0.00598526  '], time:1.331329ms
         mma(stage2): ['-0.05450439 ', '-0.03857422 ', '0.00598526  '], time:1.311874ms
             (flash): ['-0.05456543 ', '-0.03857422 ', '0.0059967   '], time:0.760818ms
----------------------------------------------------------------------------------------------------
```
