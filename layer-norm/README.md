# LayerNorm

## 0x00 说明

包含以下内容：

- [X] layer_norm_f32_kernel 
- [X] layer_norm_f32x4_kernel
- [X] layer_norm_f16_f16_kernel
- [X] layer_norm_f16x2_f16_kernel
- [X] layer_norm_f16x8_f16_kernel
- [X] layer_norm_f16x8_pack_f16_kernel
- [X] layer_norm_f16_f32_kernel
- [X] PyTorch bindings

## 测试

```bash
# 只测试Ada架构 不指定默认编译所有架构 耗时较长
export TORCH_CUDA_ARCH_LIST=Ada 
python3 layer_norm.py
```

输出:

```bash
-------------------------------------------------------------------------------------
                                        N=4096, K=512
-------------------------------------------------------------------------------------
          out_f32: ['-1.76292217 ', '0.04765211  ', '0.50859255  '], time:0.01897240ms
        out_f32x4: ['-1.76292217 ', '0.04765211  ', '0.50859255  '], time:0.00600266ms
       out_f32_th: ['-1.76119995 ', '0.04760556  ', '0.50809568  '], time:0.07085347ms
-------------------------------------------------------------------------------------
       out_f16f16: ['-1.76367188 ', '0.04763794  ', '0.50878906  '], time:0.01869035ms
       out_f16f32: ['-1.76367188 ', '0.04766846  ', '0.50878906  '], time:0.01897883ms
     out_f16x2f16: ['-1.76367188 ', '0.04766846  ', '0.50878906  '], time:0.00951219ms
     out_f16x8f16: ['-1.76367188 ', '0.04766846  ', '0.50878906  '], time:0.00467825ms
 out_f16x8packf16: ['-1.76367188 ', '0.04763794  ', '0.50878906  '], time:0.00430202ms
       out_f16_th: ['-1.76171875 ', '0.04760742  ', '0.50830078  '], time:0.07009959ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        N=4096, K=1024
-------------------------------------------------------------------------------------
          out_f32: ['-0.65619785 ', '1.33576787  ', '-0.29172164 '], time:0.05123448ms
        out_f32x4: ['-0.65619785 ', '1.33576787  ', '-0.29172164 '], time:0.01073551ms
       out_f32_th: ['-0.65587735 ', '1.33511555  ', '-0.29157916 '], time:0.07034254ms
-------------------------------------------------------------------------------------
       out_f16f16: ['-0.65576172 ', '1.3359375   ', '-0.29174805 '], time:0.05320668ms
       out_f16f32: ['-0.65576172 ', '1.3359375   ', '-0.29150391 '], time:0.05061388ms
     out_f16x2f16: ['-0.65576172 ', '1.3359375   ', '-0.29174805 '], time:0.01861978ms
     out_f16x8f16: ['-0.65576172 ', '1.3359375   ', '-0.29174805 '], time:0.00745845ms
 out_f16x8packf16: ['-0.65576172 ', '1.3359375   ', '-0.29174805 '], time:0.00648832ms
       out_f16_th: ['-0.65527344 ', '1.33398438  ', '-0.29150391 '], time:0.07068610ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        N=4096, K=2048
-------------------------------------------------------------------------------------
        out_f32x4: ['0.92044634  ', '0.37421227  ', '-2.49094558 '], time:0.02202415ms
       out_f32_th: ['0.92022169  ', '0.37412092  ', '-2.49033761 '], time:0.12026787ms
-------------------------------------------------------------------------------------
     out_f16x2f16: ['0.92041016  ', '0.37426758  ', '-2.49023438 '], time:0.05346847ms
     out_f16x8f16: ['0.92041016  ', '0.37426758  ', '-2.49023438 '], time:0.01381087ms
 out_f16x8packf16: ['0.92041016  ', '0.37426758  ', '-2.49023438 '], time:0.01159072ms
       out_f16_th: ['0.92041016  ', '0.37426758  ', '-2.49023438 '], time:0.08454061ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        N=4096, K=4096
-------------------------------------------------------------------------------------
        out_f32x4: ['-2.05339074 ', '0.25924587  ', '0.42393678  '], time:0.18885875ms
       out_f32_th: ['-2.05314016 ', '0.25921422  ', '0.42388505  '], time:0.77834105ms
-------------------------------------------------------------------------------------
     out_f16x8f16: ['-2.05273438 ', '0.2590332   ', '0.42382812  '], time:0.03327322ms
 out_f16x8packf16: ['-2.05273438 ', '0.2590332   ', '0.42382812  '], time:0.02402687ms
       out_f16_th: ['-2.05273438 ', '0.2590332   ', '0.42382812  '], time:0.17436218ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        N=4096, K=8192
-------------------------------------------------------------------------------------
     out_f16x8f16: ['-1.0234375  ', '-0.3371582  ', '-1.54882812 '], time:0.19311237ms
 out_f16x8packf16: ['-1.0234375  ', '-0.33691406 ', '-1.54882812 '], time:0.18668032ms
       out_f16_th: ['-1.0234375  ', '-0.33691406 ', '-1.54882812 '], time:0.84443021ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        N=8192, K=8192
-------------------------------------------------------------------------------------
     out_f16x8f16: ['-1.03320312 ', '0.41455078  ', '-0.49707031 '], time:0.38361049ms
 out_f16x8packf16: ['-1.03320312 ', '0.41455078  ', '-0.49707031 '], time:0.40809250ms
       out_f16_th: ['-1.03320312 ', '0.41455078  ', '-0.49707031 '], time:1.99517584ms
-------------------------------------------------------------------------------------
```
