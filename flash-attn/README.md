# FlashAttention

## 0x00 说明

包含以下内容：

- [X] flash_attn_1_fwd_f32_kernel 
- [ ] flash_attn_2_fwd_f32_kernel
- [ ] flash_attn_2_fwd_f16_kernel
- [x] flash_attn_2_fwd_f16_mma_m16n8k16_kernel
- [X] PyTorch bindings

### 运行测试   
```bash
python3 flash_attn.py
```
日志如下：
```bash
--------------------------------------------------------------------------------
       out_fa1f32: [0.19290809, -0.3947798, 0.15274261], time:2.33653069ms
   out_fa1f32(v2): [0.19290809, -0.3947798, 0.15274261], time:2.23409534ms
   out_attnf32_th: [0.19290812, -0.3947798, 0.15274265], time:0.11479020ms
--------------------------------------------------------------------------------
    out_fa2mmaf16: [0.19299316, -0.39428711, 0.15270996], time:0.03530025ms
out_fa2mmaf16(v2): [0.19299316, -0.39428711, 0.15270996], time:0.02728224ms
   out_attnf16_th: [0.19287109, -0.39477539, 0.15270996], time:0.07929444ms
--------------------------------------------------------------------------------
```
