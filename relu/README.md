# Relu

## 0x00 说明

包含以下内容：

- [X] relu_f32_kernel
- [X] relu_f32x4_kernel(float4向量化版本)
- [X] relu_f16_kernel(fp16版本)
- [X] relu_f16x2_kernel(fp16向量化版本)
- [X] relu_f16x8_kernel(fp16向量化版本)
- [X] PyTorch bindings


## 测试

```bash
# 只测试Ada架构 不指定默认编译所有架构 耗时较长
export TORCH_CUDA_ARCH_LIST=Ada 
python3 relu.py
```

输出:

```bash
--------------------------------------------------------------------------------
        out_f32: [0.0, 0.0], time:0.01072860ms
      out_f32x4: [0.0, 0.0], time:0.01059222ms
     out_f32_th: [0.0, 0.0], time:0.00772071ms
--------------------------------------------------------------------------------
        out_f16: [0.0, 0.0], time:0.01077199ms
      out_f16x2: [0.0, 0.0], time:0.01084924ms
      out_f16x8: [0.0, 0.0], time:0.01083326ms
     out_f16_th: [0.0, 0.0], time:0.00762105ms
--------------------------------------------------------------------------------
    out_f32(v2): [0.0, 0.0], time:0.00346351ms
  out_f32x4(v2): [0.0, 0.0], time:0.00342798ms
     out_f32_th: [0.0, 0.0], time:0.01125073ms
--------------------------------------------------------------------------------
    out_f16(v2): [0.0, 0.0], time:0.00343585ms
  out_f16x2(v2): [0.0, 0.0], time:0.00339842ms
  out_f16x8(v2): [0.0, 0.0], time:0.00347090ms
     out_f16_th: [0.0, 0.0], time:0.00776792ms
--------------------------------------------------------------------------------
```
